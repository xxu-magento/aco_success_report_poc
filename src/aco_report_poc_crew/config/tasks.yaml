# This file defines the tasks used in the ACO Success Metrics Report workflow.

# ---------- IMPACT ANALYZER --------------
analyze_impact_attribution_task:
  agent: impact_analyzer_agent
  description: >
    • Input Data: {{payload}}
    • The input is a JSON object shaped like:
      {
        "<initiative_id|NO_INITIATIVE>": {
          "initiative_name": "<string>",
          "overall": {
            "metrics": {
              "<metric_code>": {
                "current_avg": <number>,
                "change": "<+/-X%>",
                "initiative_sig": <true|false>,
                "overall_sig": <true|false>,
                "explanation": "<string>"
              }
            }
          }
        },
        "initiatives":[...]
      }
    • If initiatives list from the input is not empty ->  
      For every metric inside overall.metrics:
      • Look up the matching object in initiatives (same initiative_id).
      • Enrich the existing explanation with any extra context provided for that initiative.
      • Rephrase each updated explanation so it is friendly, engaging, and crystal-clear, no-jargon.
      • Never invent numbers, initiatives, or facts; only use data already in the JSON.
    • **Return** an object structured as:
         {
           "<initiative_id|NO_INITIATIVE>": {
              "initiative_name": "<string>",
              "<dimension>": {
               "metrics": {
                 "<metric_code>": {
                   "current_avg": <number>,
                   "change": "<+/-X%>",
                   "initiative_sig": <true|false>,
                   "overall_sig": <true|false>,
                   "explanation": "<string>"
                 }
               }
             }
           }
         }
    • **Self-validate** 
      Call **json_schema_check**( schema_path = "schemas/analyzer_insights.schema.json" ).
       • If no issues → return the JSON.  
       • If issues → raise error so pipeline halts.
  expected_output: >
    # ----- TEMPLATE (initiative ID or "NO_INITIATIVE", repeated for each initiative and dimension) -----
    {
      "<initiative_id|NO_INITIATIVE>": {  
        "initiative_name": "<string>",
        "<dimension>": { 
          "metrics": {
            "<metric_code>": {  
              "current_avg": <current average value>,
              "change": "<+/-X%>",
              "initiative_sig": <true|false>,
              "overall_sig": <true|false>,
              "explanation": "<brief reason>"
            }
          }
        }
      }
    }
    # ----- Example (ACO Launch) -----
    {
      "INIT_001": {
       "initiative_name": "ACO Launch",                       
        "Engagement": {
          "metrics": {
            "search_conversion_rate": {
              "current_avg": 7.1,
              "change": "+9.5%",
              "initiative_sig": true,
              "overall_sig": true,
              "explanation": "Search relevance improvements after ACO Launch drove higher engagement."
            },
            "bounce_rate": {
              "current_avg": 0.35,
              "change": "-6.1%",
              "initiative_sig": true,
              "overall_sig": true,
              "explanation": "Page-load optimizations lowered immediate exits."
            }
          }
        },
        "Conversions": {
          "metrics": {
            "conversion_rate": {
              "current_avg": 0.058,
              "change": "+5.8%",
              "initiative_sig": true,
              "overall_sig": true,
              "explanation": "Streamlined checkout flow increased completions."
            }
          }
        },
        "Traffic": {
          "metrics": {
            "unique_visitors": {
              "current_avg": 120000,
              "change": "+7.2%",
              "initiative_sig": true,
              "overall_sig": true,
              "explanation": "Improved SEO visibility brought in more visitors."
            }
          }
        },
        "Revenue": {
          "metrics": {
            "revenue": {
              "current_avg": 150000,
              "change": "+11.4%",
              "initiative_sig": true,
              "overall_sig": true,
              "explanation": "Higher traffic and conversions boosted revenue."
            }
          }
        }
      },
      // If no initiatives launched:
      //   - all KPIs grouped by dimension under the key NO_INITIATIVE
      //   - each metric has a note about ongoing effects or seasonality
      //   - example below
      "NO_INITIATIVE": {
        "initiative_name": "No Initiative",
        "Engagement": {
          "metrics": {
            "search_conversion_rate": {
              "current_avg": 7.1,
              "change": "-0.4%",
              "initiative_sig": false,
              "overall_sig": false,
              "explanation": "The change is very small (statistically) and falls within the usual range, so it's not meaningful."
            }
          }
        },
        "Traffic":     { ... },
        "Conversions": { ... },
        "Revenue":     { ... }
      }
    } 

# ---------- STORY GENERATOR --------------
generate_top_highlights_task:
  agent: story_generator_agent
  description: >
    Input: analyzer_insights JSON from Impact Analyzer.
    From the input, choose the 2-3 most significant (the KPI's overall_sig is true),
    dimension-diverse improvements as highlights (e.g., Revenue + Engagement).
    If highlights is not empty →
      For each highlight:
        • Provide the dimension and KPI name
        • State the quantified change (e.g., "+11.4% YoY")
        • If the only initiative block is "NO_INITIATIVE" →
            Write the sentence exactly as the following (DO NOT invent any non-existing initiatives)
            “Change may be due to ongoing impact from earlier initiatives or external factors. Consider expanding the date window.”.
          Else → 
            Write one or two concise sentences linking the change to its initiatives. 
            Do not invent any non-existing facts
    Output must be a JSON object containing key as "Top Highlights" and value as an array of highlight objects. 
  expected_output: >
    # ----- TEMPLATE (2-3 highlight objects total)-----
    {
    "Top Highlights":
      [
          {
            "dimension": "<Traffic|Engagement|Conversions|Revenue>",
            "metric": "<metric_code>",
            "change": "<+/-X% or value>",
            "summary": "<one or two sentences narrative>"
          }
      ]
    }
    # ----- EXAMPLE (ACO Launch) -----
    {
    "Top Highlights":
      [
        {
          "dimension": "Revenue",
          "metric": "revenue",
          "change": "+11.4%",
          "summary": "Revenue climbed 11.4% after ACO Launch, driven by higher traffic and conversion efficiency."
        },
        {
          "dimension": "Engagement",
          "metric": "search_conversion_rate",
          "change": "+9.5%",
          "summary": "Search conversion improved 9.5% following enhanced relevance and faster results."
        },
        {
          "dimension": "Traffic",
          "metric": "unique_visitors",
          "change": "+7.2%",
          "summary": "Unique visitors grew 7.2% as the optimized storefront gained greater organic visibility."
        }
      ]
    }

generate_dimension_pages_task:
  agent: story_generator_agent
  description: >
    Input: analyzer_insights JSON from Impact Analyzer.
    For each business dimension (Traffic, Engagement, Conversions, Revenue),
    create:
      • "insight_summary": 
        If the only initiative block is "NO_INITIATIVE" →
            If overall_sig of any KPI under the dimension is true →
              write the narrative exactly as the following (DO NOT invent any non-existing initiatives)
              “Change may be due to ongoing impact from earlier initiatives or external factors. Consider expanding the date window.”.
              Rephrase this sentence so it is friendly, engaging, and crystal-clear—no-jargon.
              Never invent numbers, initiatives, or facts; only use data already in the JSON.
            Else →
              write the narrative exactly as the following 
              "The change is very small (statistically) and falls within the usual range, so it's not meaningful."
              Rephrase this sentence so it is friendly, engaging, and crystal-clear—no jargon.
              Never invent numbers, initiatives, or facts; only use data already in the JSON.
        Else → 
            Write 2-3 sentence narrative linking the change to its related initiatives. 
            Keep the tone friendly, engaging, and clear.
      • "metrics": copy each KPI's current_avg, change, explanation, add last_updated and source
      • "discarded": an empty array (for now, to be filled by Report Corrector)
    Output must be a JSON object with each dimension as a key. 
  expected_output: >
    # ----- TEMPLATE (repeated for Traffic, Engagement, Conversions, Revenue) -----
      {
        "<dimension>": {
          "insight_summary": "<2-3 sentence narrative>",
          "metrics": {
            "<metric_code>": {
              "current_avg": "<current average value>",
              "change": "<+/-X%>",
              "explanation": "<brief reason>",
              "last_updated": "<ISO-8601>",
              "source": "Storefront Events"
            }
          },
          "discarded": []
        }
      }
    # ----- EXAMPLE (ACO Launch) -----
      {
        "Traffic": {
          "insight_summary": "Traffic grew steadily post-launch, with unique visitors up 7.2%, pointing to stronger site discoverability.",
          "metrics": {
            "unique_visitors": {
              "current_avg": "<current average value>",
              "change": "+7.2%",
              "explanation": "Improved SEO visibility and faster storefront attracted more visitors.",
              "last_updated": "2025-07-30T12:34:00Z",
              "source": "Storefront Events"
            }
          },
          "discarded": [] 
        },
        "Engagement": {
          "insight_summary": "User engagement strengthened: search conversion up 9.5% and bounce down 6.1%, reflecting a smoother shopping journey.",
          "metrics": {
            "search_conversion_rate": {
              "current_avg": "<current average value>",
              "change": "+9.5%",
              "explanation": "Enhanced relevance boosted on-site search success."
            },
            "bounce_rate": {
              "current_avg": "<current average value>",
              "change": "-6.1%",
              "explanation": "Faster load times reduced single-page exits.",
              "last_updated": "2025-07-30T12:34:00Z",
              "source": "Storefront Events"
            }
          },
          "discarded": []
        },
        "Conversions": {
          "insight_summary": "Conversion rate lifted 5.8%, confirming checkout flow optimizations.",
          "metrics": {
            "conversion_rate": {
              "current_avg": "<current average value>",
              "change": "+5.8%",
              "explanation": "Streamlined checkout encouraged completions.",
              "last_updated": "2025-07-30T12:34:00Z",
              "source": "Storefront Events"
            }
          },
          "discarded": []
        },
        "Revenue": {
          "insight_summary": "Revenue advanced 11.4% post-launch, outpacing traffic growth and indicating higher basket efficiency.",
          "metrics": {
            "revenue": {
              "current_avg": "<current average value>",
              "change": "+11.4%",
              "explanation": "Higher traffic and conversions boosted sales.",
              "last_updated": "2025-07-30T12:34:00Z",
              "source": "Storefront Events"
            }
          },
          "discarded": []
        }
      }

combine_stories_task:
  agent: story_generator_agent
  description: >
    You receive two inputs:

      • **highlights_json**   - output of *generate_top_highlights_task*
      • **dimensions_json**   - output of *generate_dimension_pages_task*

    **Goal:** produce a single JSON that contains:

      - Key **"Top Highlights"**   → value = highlights_json["Top Highlights"]
      - Keys **"Traffic"**, **"Engagement"**, **"Conversions"**, **"Revenue"**
        → copied verbatim from dimensions_json

    Notes:
      • Do **not** rename or nest the result under any new key.
      • Preserve all numbers and text exactly as received.
    Output the merged stories_data JSON.

  expected_output: >
    # ----- TEMPLATE -----
    {
      "Top Highlights": [ ... ],
      "Traffic":     { ... },
      "Engagement":  { ... },
      "Conversions": { ... },
      "Revenue":     { ... }
    }
    # ----- EXAMPLE -----
    {
      "Top Highlights": [
        {"dimension":"Revenue","metric":"revenue","change":"+11.4%","summary":"..."}
      ],
      "Traffic": {
        "insight_summary": "...",
        "metrics": { "unique_visitors": { ... } },
        "discarded": []
      },
      "Engagement":  { ... },
      "Conversions": { ... },
      "Revenue":     { ... }
    }


# ---------- REPORT VALIDATOR --------------
validate_final_report_task:
  agent: report_validator_agent
  description: >
    Inputs:
      • stories_data      output from the Story Generator (combine_stories_task)
      • analyzer_insights   output from the Impact Analyzer
    Steps:
      1. json_schema_check → flag structural errors. If it fails, the crew halts. 
      2. reference_matcher → ensure every metric_code, dimension, and
         initiative_id in stories_data exists in analyzer_insights.
      3. compliance_linter → flag prohibited or misleading phrases.
      • The "location" field in each issue **must be a JSON Pointer (RFC-6901)** beginning with "/", 
      e.g.,"/Engagement/metrics/bounce_rate".
      4. Return validation_report JSON with "approved" flag and issues list.
  expected_output: >
    # ---------- TEMPLATE ----------
    {
      "approved": <true|false>,
      "issues": [
        {
          "type": "<structure|reference|compliance>",
          "location": "<JSON pointer or narrative context>",
          "message": "<human-readable explanation>"
        }
      ]
    }
    # ---------- EXAMPLE ----------
    {
      "approved": false,
      "issues": [
        {
          "type": "reference",
          "location": "/Traffic/metrics/average_order_value",
          "message": "Metric code 'average_order_value' not found in analyzer payload."
        },
        {
          "type": "compliance",
          "location": "Top Highlights → Highlight #2",
          "message": "Phrase 'guaranteed profit boost' violates policy guidelines."
        }
      ]
    }

# ---------- REPORT CORRECTOR --------------
correct_report_with_validation_task:
  agent: report_corrector_agent

  description: >
    Inputs: 
      • stories_data      output from the Story Generator (combine_stories_task)
      • validation_report - output of the Report Validator  
    Steps:
      1. If validation_report.approved = false - for every object in
        `validation_report.issues`  
          •  Read its `location` field (RFC-6901 JSON Pointer, e.g.
            `/Engagement/metrics/bounce_rate`).  
          •  Split the pointer into path segments and traverse `stories_data`
            to the offending item.  
          •  Remove that item from its parent and append it to a
            `"discarded"` array inside the same parent  
            (create the array if it doesn't exist).  
          •  Preserve all original fields and add a `"reason"` key set to
            `issue.message`.  
          •  Leave all other, validated items untouched.  
          •  **Never** invent new metrics, stories, or numbers - only relocate or annotate items flagged by the Validator.
      2. **Output**  
          - If validation_report.approved = true → return the original `stories_data`.  
          - Else → return the corrected 'stories_data' JSON that still contains:  
              * "Top Highlights"  
              * the four dimension blocks  
              * any `"discarded"` arrays with attached reasons  
      3. Finally call **json_schema_check** with  
        `schema_path = "schemas/stories_data.schema.json"`; raise an error if
        the schema fails and stops the pipeline. Do not output the failed output. 

  expected_output: >
    // ---------- TEMPLATE (repeat for Traffic, Engagement, Conversions, Revenue) ----------
    {
      "Top Highlights": [ /* validated highlights */ ],
 
      "<dimension>": {
        "insight_summary": "<string>",
        "metrics": { /* only validated KPIs */ },
        "discarded": [
          {
            /* item removed from metrics or stories */
            "reason": "<validation message>"
          }
        ]
      }
    }
    // ---------- EXAMPLE ----------
    {
      "Top Highlights": [
        {
          "dimension": "Revenue",
          "metric": "revenue",
          "change": "+11.4%",
          "summary": "Revenue climbed 11.4% after ACO Launch, driven by higher traffic and conversion efficiency."
        }
      ],
      "Engagement": {
        "insight_summary": "User engagement strengthened…",
        "metrics": {
          "search_conversion_rate": {
            "current_avg": 7.1,
            "change": "+9.5%",
            "explanation": "Enhanced relevance boosted search success.",
            "last_updated": "2025-07-30T12:34:00Z",
            "source": "Storefront Events"
          }
        },
        "discarded": [
          {
            "metric_code": "bounce_rate",
            "current_avg": 0.35,
            "change": "-6.1%",
            "explanation": "Faster load times reduced exits.",
            "last_updated": "2025-07-30T12:34:00Z",
            "source": "Storefront Events",
            "reason": "Metric code 'bounce_rate' was missing supporting data (reference issue)."
          }
        ]
      },
      "Traffic":     { /* validated & discarded items */ },
      "Conversions": { /* ... */ },
      "Revenue":     { /* ... */ }
    }